{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39dc822a",
   "metadata": {},
   "source": [
    "# Fine-tuning on Pre-trained Model with Batch Integration\n",
    "In this tutorial, we demonstrate how to fine-tune a pre-trained model on a new dataset for the batch integration task. We use the PBMC 10K dataset as an example and fine-tune on the pre-trained whole-body model. \n",
    "\n",
    "We summarize the fine-tuning pipeline in the following steps, which can be used as a general recipe for finetuning on integration tasks and beyond: \n",
    "\n",
    "     1. Specify hyper-parameter setup for integration task\n",
    "     \n",
    "     2. Load pre-trained scGPT model\n",
    "     \n",
    "     3. Load and pre-process data\n",
    "     \n",
    "     4. Finetune scGPT with task-specific objectives\n",
    "     \n",
    "     5. Evaluate fine-tuned scGPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfdaaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "/h/chloexq/.cache/pypoetry/virtualenvs/scgpt--qSLVbd1-py3.9/lib/python3.7/site-packages/scanpy/_settings.py:447: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  IPython.display.set_matplotlib_formats(*ipython_format)\n"
     ]
    }
   ],
   "source": [
    "# Import required packages\n",
    "import copy\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from typing import List, Tuple, Dict, Union, Optional\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import numpy as np\n",
    "import wandb\n",
    "from scipy.sparse import issparse\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.vocab import Vocab\n",
    "from torchtext._torchtext import (\n",
    "    Vocab as VocabPybind,\n",
    ")\n",
    "\n",
    "from scgpt.tokenizer.gene_tokenizer import GeneVocab\n",
    "\n",
    "import scgpt as scg\n",
    "from scgpt.model import TransformerModel, AdversarialDiscriminator\n",
    "from scgpt.tokenizer import tokenize_and_pad_batch, random_mask_value\n",
    "from scgpt.loss import (\n",
    "    masked_mse_loss,\n",
    "    masked_relative_error,\n",
    "    criterion_neg_log_bernoulli,\n",
    ")\n",
    "from scgpt.preprocess import Preprocessor\n",
    "from scgpt import SubsetsBatchSampler\n",
    "from scgpt.utils import set_seed, category_str2int, eval_scib_metrics\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "os.environ[\"KMP_WARNINGS\"] = \"off\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2cd9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92627a2b",
   "metadata": {},
   "source": [
    "# Step 1: Specify hyper-parameter setup for integration task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb237277",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_defaults = dict(\n",
    "    seed=42,\n",
    "    dataset_name=\"PBMC_10K\", # name of the dataset to fine-tune on\n",
    "    do_train=True, # whether to update model parameters during fine-tuning\n",
    "    load_model=\"/scratch/ssd004/datasets/cellxgene/save/cellxgene_census_human-May23-08-36-2023\", # path to pre-trained model\n",
    "    mask_ratio=0.4, # default mask_ratio\n",
    "    epochs=30, # default fine-tuning epochs\n",
    "    n_bins=51, # default number of bins\n",
    "    GEPC=True, # Masked value prediction for cell embedding\n",
    "    ecs_thres=0.8,  # Elastic cell similarity objective, 0.0 to 1.0, 0.0 to disable\n",
    "    dab_weight=1.0,\n",
    "    lr=1e-4,\n",
    "    batch_size=64,\n",
    "    layer_size=128,\n",
    "    nlayers=4,\n",
    "    nhead=4,\n",
    "    # if load model, batch_size, layer_size, nlayers, nhead will be ignored\n",
    "    dropout=0.2,\n",
    "    schedule_ratio=0.9,  # ratio of epochs for learning rate schedule\n",
    "    save_eval_interval=5,\n",
    "    log_interval=100,\n",
    "    fast_transformer=True,\n",
    "    pre_norm=False,\n",
    "    amp=True, # Automatic Mixed Precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7dafe79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hyperparameter_defaults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6783/2245360855.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyperparameter_defaults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hyperparameter_defaults' is not defined"
     ]
    }
   ],
   "source": [
    "hyperparameter_defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346aeb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/scratch/ssd004/datasets/cellxgene/save/cellxgene_census_human-May23-08-36-2023\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed6778",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    config=hyperparameter_defaults,\n",
    "    project=\"scGPT\",\n",
    "    reinit=True,\n",
    "    settings=wandb.Settings(start_method=\"fork\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
